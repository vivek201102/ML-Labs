{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17SEdzCXg1pt3V0irrK-yY8PIysvabpjM",
      "authorship_tag": "ABX9TyPERMqPv5+m2gp91J0xM7KG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek201102/ML-Labs/blob/master/Lab_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 04 "
      ],
      "metadata": {
        "id": "zVjMo_KJE7-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R5sYjbnsQS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69369d88-fe3a-4c3f-cf62-b93ed9fc7f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 877 1912 1567 3265 1726]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3854896.8"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Single feature\n",
        "input = np.array([73,91,87,102,69])\n",
        "target = np.array([56,81,119,22,103])\n",
        "weight = np.array([12,21,18,32,25])\n",
        "bias = np.array([1,1,1,1,1])\n",
        "\n",
        "prediction = (input * weight) + bias\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "MSE = np.square(np.subtract(target, prediction)).mean()\n",
        "MSE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56], [81], [119], [22], [103] ], dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "\n",
        "# To divide dataset into the batches\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# torch,randn generates random value matrix such that mean = 0 and variance = 1\n",
        "\n",
        "# 1x3 random value matrix\n",
        "weight = torch.randn(1,3, requires_grad=True)\n",
        "\n",
        "# # 1x1 random value matrix\n",
        "biass = torch.rand(1, requires_grad=True)\n",
        "\n",
        "\n",
        "# w = np.array([0.2590, 0.3474, 0.3161], dtype='float32')\n",
        "# b = np.array([0.2950], dtype='float32')\n",
        "\n",
        "# weight = torch.tensor(w, requires_grad=True)\n",
        "# biass = torch.tensor(b, requires_grad=True)\n",
        "\n",
        "print(\"\\n\\nIntial weights: \", weight)\n",
        "print(\"Intail bias:\", biass, \"\\n\\n\")\n",
        "\n",
        "def mse_loss_function(prediction, target):\n",
        "  difference = prediction - target\n",
        "  difference_square = difference * difference\n",
        "  return torch.sum(difference_square) /difference.numel() \n",
        "\n",
        "\n",
        "\n",
        "def model(X):\n",
        "  return X @ weight.T + biass # input matrix and weight matrix multiplication and add bias\n",
        "\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print(\"Initial Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "  print(\"Initial Loss: \", mse_loss_function(prediction, y))\n",
        "\n",
        "# Training\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    loss = mse_loss_function(preds, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      weight -= weight.grad * 1e-5\n",
        "      biass -= biass.grad * 1e-5\n",
        "\n",
        "      weight.grad.zero_()\n",
        "      biass.grad.zero_()\n",
        "\n",
        "\n",
        "# Final\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "  print(\"Final Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Final Loss: \", mse_loss_function(prediction, y))\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Exercise\n",
        "pred = model(torch.from_numpy(np.array([70, 34, 45], dtype='float32')))\n",
        "print(pred) # 31.3134\n",
        "\n",
        "\n",
        "print(\"\\n\\nFinal weights: \", weight)\n",
        "print(\"Final bias:\", biass, \"\\n\\n\")"
      ],
      "metadata": {
        "id": "ZLW4W4Gg1q2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25484701-06c4-4606-c696-55f924f5b887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Intial weights:  tensor([[-0.9968, -0.4612,  0.3198]], requires_grad=True)\n",
            "Intail bias: tensor([0.1594], requires_grad=True) \n",
            "\n",
            "\n",
            "Initial Prediction:  tensor([[ -89.7592],\n",
            "        [-109.5177],\n",
            "        [ -90.5123],\n",
            "        [-110.6720]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[ 56.],\n",
            "        [ 22.],\n",
            "        [103.],\n",
            "        [ 81.]])\n",
            "Initial Loss:  tensor(28181.9492, grad_fn=<DivBackward0>)\n",
            "Initial Prediction:  tensor([[-129.8182]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[119.]])\n",
            "Initial Loss:  tensor(61910.4922, grad_fn=<DivBackward0>)\n",
            "\n",
            "\n",
            "Final Prediction:  tensor([[118.3169],\n",
            "        [ 82.0095],\n",
            "        [101.7572],\n",
            "        [ 57.0311]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[119.],\n",
            "        [ 81.],\n",
            "        [103.],\n",
            "        [ 56.]])\n",
            "Final Loss:  tensor(1.0234, grad_fn=<DivBackward0>)\n",
            "\n",
            "\n",
            "Final Prediction:  tensor([[20.9577]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[22.]])\n",
            "Final Loss:  tensor(1.0863, grad_fn=<DivBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tensor([31.7563], grad_fn=<AddBackward0>)\n",
            "\n",
            "\n",
            "Final weights:  tensor([[-0.4024,  0.8443,  0.6901]], requires_grad=True)\n",
            "Final bias: tensor([0.1655], requires_grad=True) \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 04 _ 1"
      ],
      "metadata": {
        "id": "7yn9RZ7sFAKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37],[69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69,96, 70],\n",
        "                   [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96,70]], dtype='float32')\n",
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],\n",
        "[56, 70], [81, 101], [119, 133], [22, 37], [103, 119]],dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs,targets)\n",
        "\n",
        "# Dataset loader\n",
        "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
        "\n",
        "next(iter(train_dl))\n",
        "\n",
        "# Generate randomly such that 3 features and 2 output\n",
        "model = nn.Linear(3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)\n",
        "\n",
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)\n",
        "\n",
        "\n",
        "def fit(num_epoches, model, loss_fn, opt):\n",
        "  for epoch in range(num_epoches):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_fn(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "fit(10000, model, loss_fn, opt)\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "print(target)"
      ],
      "metadata": {
        "id": "D7GHsfzGFCEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rate - 0.1\n",
        "Epoch - 1000"
      ],
      "metadata": {
        "id": "dCnUjbs9WnyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56], [81], [119], [22], [103] ], dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "\n",
        "# To divide dataset into the batches\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# torch,randn generates random value matrix such that mean = 0 and variance = 1\n",
        "\n",
        "# 1x3 random value matrix\n",
        "weight = torch.randn(1,3, requires_grad=True)\n",
        "\n",
        "# 1x1 random value matrix\n",
        "biass = torch.rand(1, requires_grad=True)\n",
        "\n",
        "def mse_loss_function(prediction, target):\n",
        "  difference = prediction - target\n",
        "  difference_square = difference * difference\n",
        "  return torch.sum(difference_square) /difference.numel() \n",
        "\n",
        "\n",
        "\n",
        "def model(X):\n",
        "  return X @ weight.T + biass # input matrix and weight matrix multiplication and add bias\n",
        "\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print(\"Initial Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "  print(\"Initial Loss: \", mse_loss_function(prediction, y))\n",
        "\n",
        "# Training\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    loss = mse_loss_function(preds, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      weight -= weight.grad * 1e-1\n",
        "      biass -= biass.grad * 1e-1\n",
        "\n",
        "      weight.grad.zero_()\n",
        "      biass.grad.zero_()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Final\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "  print(\"Final Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "  print(\"Final Loss: \", mse_loss_function(prediction, y))"
      ],
      "metadata": {
        "id": "0wM6wTMYVVL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c343f212-1fd4-47ee-fe48-dd0ea8bef236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Prediction:  tensor([[ 81.6000],\n",
            "        [135.7523],\n",
            "        [ 88.7516],\n",
            "        [ 59.1859]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[ 56.],\n",
            "        [119.],\n",
            "        [ 81.],\n",
            "        [103.]])\n",
            "Initial Loss:  tensor(728.9407, grad_fn=<DivBackward0>)\n",
            "Initial Prediction:  tensor([[105.1328]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[22.]])\n",
            "Initial Loss:  tensor(6911.0669, grad_fn=<DivBackward0>)\n",
            "\n",
            "\n",
            "Final Prediction:  tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[ 81.],\n",
            "        [ 22.],\n",
            "        [ 56.],\n",
            "        [103.]])\n",
            "Final Loss:  tensor(nan, grad_fn=<DivBackward0>)\n",
            "\n",
            "\n",
            "Final Prediction:  tensor([[nan]], grad_fn=<AddBackward0>)\n",
            "Actual:  tensor([[119.]])\n",
            "Final Loss:  tensor(nan, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56], [81], [119], [22], [103] ], dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "\n",
        "# To divide dataset into the batches\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# torch,randn generates random value matrix such that mean = 0 and variance = 1\n",
        "\n",
        "# 1x3 random value matrix\n",
        "weight = torch.randn(1,3, requires_grad=True)\n",
        "\n",
        "# 1x1 random value matrix\n",
        "biass = torch.rand(1, requires_grad=True)\n",
        "\n",
        "def mse_loss_function(prediction, target):\n",
        "  difference = prediction - target\n",
        "  difference_square = difference * difference\n",
        "  return torch.sum(difference_square) /difference.numel() \n",
        "\n",
        "\n",
        "\n",
        "def model(X):\n",
        "  return X @ weight.T + biass # input matrix and weight matrix multiplication and add bias\n",
        "\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print(\"Initial Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "  print(\"Initial Loss: \", mse_loss_function(prediction, y))\n",
        "\n",
        "\n",
        "# Training\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    loss = mse_loss_function(preds, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      weight -= weight.grad * 1e-5\n",
        "      biass -= biass.grad * 1e-5\n",
        "\n",
        "      weight.grad.zero_()\n",
        "      biass.grad.zero_()\n",
        "\n",
        "\n",
        "# Final\n",
        "for x, y in train_loader:\n",
        "  prediction = model(x)\n",
        "\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "  print(\"Final Prediction: \", prediction)\n",
        "  print(\"Actual: \", y)\n",
        "\n",
        "  print(\"Final Loss: \", mse_loss_function(prediction, y))\n",
        "\n",
        "pred = model(torch.from_numpy(np.array([70, 34, 45], dtype='float32')))\n",
        "print(\"For exercise:\" ,pred)"
      ],
      "metadata": {
        "id": "1dD1M9FZW8-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}